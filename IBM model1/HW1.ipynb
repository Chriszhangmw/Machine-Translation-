{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  第一个小作业： 编写简单的机器翻译系统 \n",
    "在课程中，我们讨论过一个简单的案例。通过统计的方式来得出了每一个单词有可能跟哪一个单词对应的关系。在这里，我们通过编写一个程序的方式来实现这个功能。 在这里，我们的任务是把第一个语言翻译成第二个语言。第一个语言用lang1来表示，第二个语言用lang2来表示。 在这里，最终的输出为 p(word_i_lang1 | word_j_lang2): 对于第二种语言里的word_j来说， 这个条件概率表示 word_i的匹配概率。 \n",
    "\n",
    "比如给定 p(ok-voon | at-voon) 表示有多大的概率at-voon可以翻译成 ok-voon. \n",
    "\n",
    "参考： \n",
    "1. tutorial2003.pdf   Page 17 - Page 23\n",
    "2. ibm-model1.pdf  Page 1 - Page 32  \n",
    "\n",
    "虽然在课程里，大概已经讲了大致的思路以及EM算法的思想，但具体细节暂时没有逐一细讲。希望结合这里给定的参考资料，能够自行编写代码来实现。Deadline之后我们会公布标准答案。 \n",
    "\n",
    "难度系数：中 （需要自行阅读一定的参考资料来完成）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PART1: 读取平行语料库数据，分别读取两个不同的文件。 第一个文件里的每一行对应第二个文件里的每一行\n",
    "pcorpus = dict()\n",
    "lines_lang1 = open(\"data_lang1.txt\", \"r\").readlines()\n",
    "lines_lang2 = open(\"data_lang2.txt\", \"r\").readlines()\n",
    "\n",
    "for line1, line2 in zip(lines_lang1, lines_lang2):\n",
    "    # 分词\n",
    "    sentence1 = tuple(word_tokenize(\"NULL \" + line1.strip(\"\\n\")))\n",
    "    sentence2 = tuple(word_tokenize(\"NULL \" + line2.strip(\"\\n\")))\n",
    "    pcorpus[sentence1] = sentence2\n",
    "print (pcorpus)\n",
    "\n",
    "## TODO 思考题：为什么这里加入了NULL字符？？？？\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PART2: TODO \n",
    "##        定义模型参数，以及初始化。 在这里，我们最后要求出来的是 p(word_i_lang1 | word_j_lang2), 也就是模型的参数。 \n",
    "##        在这里定义变量 translation_probs， 并给它一个初识的值。 \n",
    " \n",
    "translation_probs = \n",
    "print(translation_probs[\"ok-voon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PART 3: 参数学习过程。在课程里我们谈到过：  \n",
    "##         1. 在给定Alignmennt的情况下，可以很容易统计出translation_probs变量。\n",
    "##         2. 在给定translation_probs变量情况下也可以计算出alignments.  注：这时候的alignment可以看作是fractional，也就是一个概率。\n",
    "##            一个单词可以映射到不同的单词，但具备概率。 这种也可以想象成是soft alignment. \n",
    "##            由于此问题具有这样的一个特点，这个问题正好可以使用EM类的算法来解决。咱们先不关心什么叫EM算法，在这里我们来只关心，通过1.2步骤的循环最终可以\n",
    "##            可以得出合理的参数值。 \n",
    "##         大概的思路就是：\n",
    "##         for i in (num_epochs):\n",
    "##            # 根据translation_probs求出 alignments\n",
    "##            # 根据alignment, 统计出translation_probs\n",
    "##         num_epochs指的是循环次数，我们一般都会循环到直到收敛为止。 在这里，为了简单期间给定num_epochs的值。但实际上，我们需要设定一个评测\n",
    "##         收敛的标准（后续课程再讲）\n",
    "num_epochs = 1\n",
    "for i in range(num_epochs):\n",
    "    ## TODO 此处为核心的代码部分，需要循环平行语料库，同时不断更新模型参数。 \n",
    "    ##      适当参考给定的参考资料，并花时间思考问题具体怎么解决。这里的核心是不断更新translation_probs。 初次接触会发现有一定的难度，这很正常。 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PART 4: 打印结果\n",
    "print()\n",
    "print(\"{:<40}{:>40}\".format(\"t(lang1|lang2)\", \"Value\"))\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "iterations = 0\n",
    "for ((lang1_word, lang2_word), value) in sorted(translation_probs.items(), key=itemgetter(1), reverse=True):\n",
    "    print(\"{:<40}{:>40.2}\".format(\"t(%s|%s)\" % (lang1_word, lang2_word), value))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 5: 思考题\n",
    "如果使用上述的结果(translation_probs)来做翻译，比如对于“farok crrrok hihok yorok clok kantok ok-yurp”这句话，找出对应的翻译后的结果，需要如何做？ 有哪些需要考虑的点？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 6: 其他IBM Models\n",
    "在此次小作业里，我们实现的是IBM Model1. IBM Model是系列模型，除了Model1, 还有Model2,3,4,5， 其中Model1是最简单的模型，而且只考虑了\n",
    "translation_probs，没有考虑比如映射关系长度，对应的为止关系等等。 虽然IBM模型已经不是主流的机器翻译模型，但其包含的很多核心思想仍是NLP领域非常\n",
    "重要的话题，包括word alignment, nosiy channel models等。 建议感兴趣的人可以再深入学习学习， 在这里领域里学者Kevin Knight是较具有权威性的\n",
    "学者。 也可以参考： https://www.isi.edu/natural-language/mt/wkbk.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
